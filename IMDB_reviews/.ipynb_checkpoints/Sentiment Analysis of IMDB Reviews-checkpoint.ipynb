{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>IMDB Reviews Sentimental Analysis</center></h1>\n",
    "\n",
    "\n",
    "Data Source : https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "\n",
    "IMDB dataset having 50K movie reviews for natural language processing or Text analytics.\n",
    "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training and 25,000 for testing. So, predict the number of positive and negative reviews using either classification or deep learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('IMDB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    25000\n",
       "positive    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here we can see that data is fully balanced between positive or negative sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'] = data['sentiment'].map({'positive':1,'negative':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n",
      "==================================================\n",
      "This movie is awful, I can't even be bothered to write a review on this garbage! All i will say it is one of the most boring films I've ever seen.<br /><br />And the acting is very bad. The boy who plays the main character really annoys me, he's got the same expression on his face through out the movie. I just want to slap him! Basically 80% of the movie is slow motion shots of skateboarders, weird music, and utter sh*t..<br /><br />Apparently I've got to write at least 10 lines of text to submit this comment, so I'll use up a few more lines by saying the lead character has got one of those faces you just want to slap!<br /><br />Meh i give up..THIS MOVIE SUCKS !!!!\n",
      "==================================================\n",
      "Oh dear god. This was horrible. There is bad, then there was this. This movie makes no sense at all. It runs all over the map and isn't clear about what its saying at all. The music seemed like it was trying to be like Batman. The fact that 'Edison' isn't a real city, takes away. Since I live in Vancouver, watching this movie and recognizing all these places made it unbearable. Why didn't they make it a real city? The only writing that was decent was'Tilman' in which John Heard did a fantastic job. He was the only actor who played his role realistically and not over the top and campy. It was actually a shame to see John Heard play such a great bad guy with a lot of screen time, and the movie be a washout. Too bad. Hopefully someone important will see it, and at least give John Heard credit where credit is due, and hire him as lead bad guy again, which is where he should be. on the A List.\n",
      "==================================================\n",
      "I was attracted to this film by its offbeat, low-key, 'real life' story line. That is, a twenty-something guy flops in the Big Apple and comes back home to live with his parents and even more floppy brother. It just might have worked but there's a problem. And that problem's name is Casey Affleck. <br /><br />Casey Affleck is nearly catatonic in this film. His acting mantra must be \"exert as little effort as possible at all times\". Or \"why speak when you can mutter?\" Or maybe \"put yourself into a coma as soon as the camera rolls\". Lips moving when speaking? Barely. Facial expressions? None. Muscles in face? Atrophied. Something? Nothing. ANYthing? Zip.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "sent_0 = data['review'].values[0]\n",
    "print(sent_0)\n",
    "print('='*50)\n",
    "\n",
    "sent_1000 = data['review'].values[1000]\n",
    "print(sent_1000)\n",
    "print('='*50)\n",
    "\n",
    "sent_1500 = data['review'].values[1500]\n",
    "print(sent_1500)\n",
    "print('='*50)\n",
    "\n",
    "sent_4900 = data['review'].values[4900]\n",
    "print(sent_4900)\n",
    "print('='*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_0 = re.sub(r\"http\\s\",\"\",sent_0)\n",
    "sent_1000 = re.sub(r\"http\\s\",\"\",sent_1000)\n",
    "sent_1500 = re.sub(r\"http\\s\",\"\",sent_1500)\n",
    "sent_4900 = re.sub(r\"http\\s\",\"\",sent_4900)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Removed http or https from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n"
     ]
    }
   ],
   "source": [
    "print(sent_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing all html tags by BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n",
      "==================================================\n",
      "This movie is awful, I can't even be bothered to write a review on this garbage! All i will say it is one of the most boring films I've ever seen.And the acting is very bad. The boy who plays the main character really annoys me, he's got the same expression on his face through out the movie. I just want to slap him! Basically 80% of the movie is slow motion shots of skateboarders, weird music, and utter sh*t..Apparently I've got to write at least 10 lines of text to submit this comment, so I'll use up a few more lines by saying the lead character has got one of those faces you just want to slap!Meh i give up..THIS MOVIE SUCKS !!!!\n",
      "==================================================\n",
      "Oh dear god. This was horrible. There is bad, then there was this. This movie makes no sense at all. It runs all over the map and isn't clear about what its saying at all. The music seemed like it was trying to be like Batman. The fact that 'Edison' isn't a real city, takes away. Since I live in Vancouver, watching this movie and recognizing all these places made it unbearable. Why didn't they make it a real city? The only writing that was decent was'Tilman' in which John Heard did a fantastic job. He was the only actor who played his role realistically and not over the top and campy. It was actually a shame to see John Heard play such a great bad guy with a lot of screen time, and the movie be a washout. Too bad. Hopefully someone important will see it, and at least give John Heard credit where credit is due, and hire him as lead bad guy again, which is where he should be. on the A List.\n",
      "==================================================\n",
      "I was attracted to this film by its offbeat, low-key, 'real life' story line. That is, a twenty-something guy flops in the Big Apple and comes back home to live with his parents and even more floppy brother. It just might have worked but there's a problem. And that problem's name is Casey Affleck. Casey Affleck is nearly catatonic in this film. His acting mantra must be \"exert as little effort as possible at all times\". Or \"why speak when you can mutter?\" Or maybe \"put yourself into a coma as soon as the camera rolls\". Lips moving when speaking? Barely. Facial expressions? None. Muscles in face? Atrophied. Something? Nothing. ANYthing? Zip.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(sent_0,'lxml')\n",
    "text = soup.get_text()\n",
    "print(text)\n",
    "print('='*50)\n",
    "\n",
    "soup = BeautifulSoup(sent_1000,'lxml')\n",
    "text = soup.get_text()\n",
    "print(text)\n",
    "print('='*50)\n",
    "\n",
    "soup = BeautifulSoup(sent_1500,'lxml')\n",
    "text = soup.get_text()\n",
    "print(text)\n",
    "print('='*50)\n",
    "\n",
    "soup = BeautifulSoup(sent_4900,'lxml')\n",
    "text = soup.get_text()\n",
    "print(text)\n",
    "print('='*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\",\"will not\",phrase)\n",
    "    phrase = re.sub(r\"can\\'t\",\"can not\",phrase)\n",
    "    \n",
    "    #genrel\n",
    "    \n",
    "    phrase = re.sub(r\"n\\'t'\",\" not\",phrase)\n",
    "    phrase = re.sub(r\"\\'re\",\" are\",phrase)\n",
    "    phrase = re.sub(r\"\\'s\",\" is\",phrase)\n",
    "    phrase = re.sub(r\"\\'d\",\" would\",phrase)\n",
    "    phrase = re.sub(r\"\\'ll\",\" will\",phrase)\n",
    "    phrase = re.sub(r\"\\'t\",\" not\",phrase)\n",
    "    phrase = re.sub(r\"\\'ve\",\" have\",phrase)\n",
    "    phrase = re.sub(r\"\\'m\",\" am\",phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh dear god. This was horrible. There is bad, then there was this. This movie makes no sense at all. It runs all over the map and isn not clear about what its saying at all. The music seemed like it was trying to be like Batman. The fact that 'Edison' isn not a real city, takes away. Since I live in Vancouver, watching this movie and recognizing all these places made it unbearable. Why didn not they make it a real city? The only writing that was decent was'Tilman' in which John Heard did a fantastic job. He was the only actor who played his role realistically and not over the top and campy. It was actually a shame to see John Heard play such a great bad guy with a lot of screen time, and the movie be a washout. Too bad. Hopefully someone important will see it, and at least give John Heard credit where credit is due, and hire him as lead bad guy again, which is where he should be. on the A List.\n"
     ]
    }
   ],
   "source": [
    "sent_1500 = decontracted(sent_1500)\n",
    "print(sent_1500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the other reviewers has mentioned that after watching just  Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\n"
     ]
    }
   ],
   "source": [
    "# removes words with numbers\n",
    "sent_0 = re.sub(\"\\S*\\d\\S*\",\"\",sent_0).strip()\n",
    "print(sent_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh dear god This was horrible There is bad then there was this This movie makes no sense at all It runs all over the map and isn not clear about what its saying at all The music seemed like it was trying to be like Batman The fact that Edison isn not a real city takes away Since I live in Vancouver watching this movie and recognizing all these places made it unbearable Why didn not they make it a real city The only writing that was decent was Tilman in which John Heard did a fantastic job He was the only actor who played his role realistically and not over the top and campy It was actually a shame to see John Heard play such a great bad guy with a lot of screen time and the movie be a washout Too bad Hopefully someone important will see it and at least give John Heard credit where credit is due and hire him as lead bad guy again which is where he should be on the A List \n"
     ]
    }
   ],
   "source": [
    "sent_1500 = re.sub('[^A-Za-z0-9]+',' ',sent_1500)\n",
    "print(sent_1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords= set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 50000/50000 [03:11<00:00, 261.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "preprocessed_reviews = []\n",
    "\n",
    "for sentence in tqdm(data['review']):\n",
    "    sentence  = re.sub(r\"http\\S+\",\"\",sentence)\n",
    "    sentence = BeautifulSoup(sentence,'lxml').get_text()\n",
    "    sentence = decontracted(sentence)\n",
    "    sentence = re.sub(\"\\S*\\d\\S*\",\"\",sentence).strip()\n",
    "    sentence = re.sub('[^A-Za-z]+',' ',sentence)\n",
    "    ps =PorterStemmer()\n",
    "    sentence = ' '.join([ps.stem(word) for word in sentence.split()])\n",
    "    sentence = ' '.join(e.lower() for e in sentence.split() if e.lower() not in stopwords)\n",
    "    preprocessed_reviews.append(sentence.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oh dear god thi wa horribl bad wa thi thi movi make no sens run map not clear say music seem like wa tri like batman fact edison not real citi take away sinc live vancouv watch thi movi recogn place made unbear whi not make real citi onli write wa decent wa tilman john heard fantast job wa onli actor play hi role realist not top campi wa actual shame see john heard play great bad guy lot screen time movi washout bad hope someon import see least give john heard credit credit due hire lead bad guy list'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_reviews[1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = preprocessed_reviews\n",
    "data.to_csv('preprocessed_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review ha mention watch oz episod hook rig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder littl product film techniqu veri unassu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought thi wa wonder way spend time hot summe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic famili littl boy jake think zombi hi clo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one review ha mention watch oz episod hook rig...          1\n",
       "1  wonder littl product film techniqu veri unassu...          1\n",
       "2  thought thi wa wonder way spend time hot summe...          1\n",
       "3  basic famili littl boy jake think zombi hi clo...          0\n",
       "4  petter mattei love time money visual stun film...          1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some feature names  ['aa', 'aaa', 'aaaaaaaaaaaahhhhhhhhhhhhhh', 'aaaaaaaargh', 'aaaaaaah', 'aaaaaaahhhhhhggg', 'aaaaagh', 'aaaaah', 'aaaaahhhh', 'aaaaargh']\n",
      "==================================================\n",
      "the type of count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\n",
      "the shape of out text BOW vectorizer  (50000, 71371)\n",
      "the number of unique words  71371\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "count_vect.fit(preprocessed_reviews)\n",
    "print(\"some feature names \",count_vect.get_feature_names()[:10])\n",
    "print(\"=\"*50)\n",
    "final_counts = counts = count_vect.transform(preprocessed_reviews)\n",
    "print(\"the type of count vectorizer \",type(final_counts))\n",
    "print(\"the shape of out text BOW vectorizer \",final_counts.get_shape())\n",
    "print(\"the number of unique words \",final_counts.get_shape()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-Grams and n-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the type of count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\n",
      "the shape of out text BoW vectorizer  (50000, 5000)\n",
      "the number of unique words including both unigrams and bigrams  5000\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(ngram_range = (1,2),min_df = 10,max_features = 5000)\n",
    "final_bigram_counts = count_vect.fit_transform(preprocessed_reviews)\n",
    "print(\"the type of count vectorizer \",type(final_bigram_counts))\n",
    "print(\"the shape of out text BoW vectorizer \",final_bigram_counts.get_shape())\n",
    "print(\"the number of unique words including both unigrams and bigrams \",final_bigram_counts.get_shape()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some sample features(unique words in the corpus) ['aa', 'aaa', 'aag', 'aaliyah', 'aam', 'aamir', 'aamir khan', 'aardman', 'aaron', 'aaron carter']\n",
      "==================================================\n",
      "the type of count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\n",
      "the shape of out text TFIDF vectorizer  (50000, 90210)\n",
      "the number of unique words including both unigrams and bigrams  90210\n"
     ]
    }
   ],
   "source": [
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2), min_df=10)\n",
    "tf_idf_vect.fit(preprocessed_reviews)\n",
    "print(\"some sample features(unique words in the corpus)\",tf_idf_vect.get_feature_names()[0:10])\n",
    "print('='*50)\n",
    "\n",
    "final_tf_idf = tf_idf_vect.transform(preprocessed_reviews)\n",
    "print(\"the type of count vectorizer \",type(final_tf_idf))\n",
    "print(\"the shape of out text TFIDF vectorizer \",final_tf_idf.get_shape())\n",
    "print(\"the number of unique words including both unigrams and bigrams \", final_tf_idf.get_shape()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "list_of_sentence = []\n",
    "for sentence in preprocessed_reviews:\n",
    "    \n",
    "    list_of_sentence.append(sentence.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('excel', 0.8256300687789917), ('fantast', 0.7941492199897766), ('good', 0.7600095272064209), ('fine', 0.7545821070671082), ('amaz', 0.7409884929656982), ('terrif', 0.7408449649810791), ('awesom', 0.7135226726531982), ('outstand', 0.7109720706939697), ('brilliant', 0.7056697607040405), ('superb', 0.6898691654205322)]\n",
      "==================================================\n",
      "[('stupidest', 0.8620564937591553), ('scariest', 0.8152726292610168), ('best', 0.7948146462440491), ('dumbest', 0.7562673687934875), ('funniest', 0.7443196177482605), ('cheesiest', 0.7083956599235535), ('wors', 0.6735664010047913), ('greatest', 0.6651947498321533), ('coolest', 0.6622195839881897), ('weirdest', 0.6475479006767273)]\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(list_of_sentence,min_count=5,size = 50,workers = 4)\n",
    "print(w2v_model.wv.most_similar('great'))\n",
    "print('='*50)\n",
    "print(w2v_model.wv.most_similar('worst'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words that occured minimum 5 times  26565\n",
      "sample words  ['one', 'review', 'ha', 'mention', 'watch', 'oz', 'episod', 'hook', 'right', 'thi', 'exactli', 'happen', 'first', 'thing', 'struck', 'wa', 'brutal', 'unflinch', 'scene', 'violenc', 'set', 'word', 'go', 'trust', 'not', 'show', 'faint', 'heart', 'timid', 'pull', 'no', 'punch', 'regard', 'drug', 'sex', 'hardcor', 'classic', 'use', 'call', 'nicknam', 'given', 'oswald', 'maximum', 'secur', 'state', 'focus', 'mainli', 'emerald', 'citi', 'experiment']\n"
     ]
    }
   ],
   "source": [
    "w2v_words = list(w2v_model.wv.vocab)\n",
    "print(\"number of words that occured minimum 5 times \",len(w2v_words))\n",
    "print(\"sample words \",w2v_words[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting text into vectors using wAvg W2V,TFIDF-W2V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Average W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 50000/50000 [00:18<00:00, 2632.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sent_vectors = []\n",
    "for sent in tqdm(list_of_sentence):\n",
    "    sent_vec = np.zeros(50)\n",
    "    cnt_words = 0\n",
    "    for word in sent:\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec+=vec\n",
    "            cnt_words+=1\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= cnt_words\n",
    "    sent_vectors.append(sent_vec)\n",
    "print(len(sent_vectors))\n",
    "print(len(sent_vectors[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* TFIDF Weighted W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TfidfVectorizer()\n",
    "model.fit(preprocessed_reviews)\n",
    "dictionary = dict(zip(model.get_feature_names(),list(model.idf_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 50000/50000 [00:57<00:00, 868.48it/s]\n"
     ]
    }
   ],
   "source": [
    "tfidf_feat = model.get_feature_names()\n",
    "\n",
    "tfidf_sent_vectors = []\n",
    "row = 0\n",
    "for sent in tqdm(list_of_sentence): # for each review/sentence \n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "#             tf_idf = tf_idf_matrix[row, tfidf_feat.index(word)]\n",
    "            # to reduce the computation we are \n",
    "            # dictionary[word] = idf value of word in whole courpus\n",
    "            # sent.count(word) = tf valeus of word in this review\n",
    "            tf_idf = dictionary[word]*(sent.count(word)/len(sent))\n",
    "            sent_vec += (vec * tf_idf)\n",
    "            weight_sum += tf_idf\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors.append(sent_vec)\n",
    "    row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
