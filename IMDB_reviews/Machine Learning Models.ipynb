{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>IMDB Reviews Sentimental Analysis</center></h1>\n",
    "\n",
    "\n",
    "Data Source : https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "\n",
    "IMDB dataset having 50K movie reviews for natural language processing or Text analytics.\n",
    "This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training and 25,000 for testing. So, predict the number of positive and negative reviews using either classification or deep learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score,classification_report,log_loss\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review ha mention watch oz episod hook rig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder littl product film techniqu veri unassu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought thi wa wonder way spend time hot summe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic famili littl boy jake think zombi hi clo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one review ha mention watch oz episod hook rig...          1\n",
       "1  wonder littl product film techniqu veri unassu...          1\n",
       "2  thought thi wa wonder way spend time hot summe...          1\n",
       "3  basic famili littl boy jake think zombi hi clo...          0\n",
       "4  petter mattei love time money visual stun film...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_reviews = pd.read_csv('preprocessed_reviews')\n",
    "preprocessed_reviews.drop('Unnamed: 0',axis = 1,inplace = True)\n",
    "preprocessed_reviews.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling the sentiment text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "lb = LabelBinarizer()\n",
    "sentiment_data  = lb.fit_transform(preprocessed_reviews['sentiment'])\n",
    "print(sentiment_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train set features (40000,)\n",
      "Shape of test set features (10000,)\n",
      "==================================================\n",
      "shape of train set labels (40000, 1)\n",
      "Shape of test set labels (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "train_preprocessed_reviews = preprocessed_reviews.review[:40000]\n",
    "test_preprocessed_reviews = preprocessed_reviews.review[40000:50000]\n",
    "print(\"Shape of train set features\",train_preprocessed_reviews.shape)\n",
    "print(\"Shape of test set features\",test_preprocessed_reviews.shape)\n",
    "print('='*50)\n",
    "train_sentiments=sentiment_data[:40000]\n",
    "test_sentiments=sentiment_data[40000:]\n",
    "print(\"shape of train set labels\",train_sentiments.shape)\n",
    "print(\"Shape of test set labels\",test_sentiments.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the type of count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\n",
      "the shape of train_reviews_cv out text BOW vectorizer  (40000, 5834102)\n",
      "the shape of test_reviews_cv out text BOW vectorizer  (10000, 5834102)\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(min_df = 0,max_df = 1,ngram_range = (1,3))\n",
    "train_reviews_cv = count_vect.fit_transform(train_preprocessed_reviews)\n",
    "test_reviews_cv = count_vect.transform(test_preprocessed_reviews)\n",
    "\n",
    "print(\"the type of count vectorizer \",type(train_reviews_cv))\n",
    "print(\"the shape of train_reviews_cv out text BOW vectorizer \",train_reviews_cv.get_shape())\n",
    "print(\"the shape of test_reviews_cv out text BOW vectorizer \",test_reviews_cv.get_shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the type of train and test count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\n",
      "the shape of train_reviews_tv out text TFIDF vectorizer  (40000, 72386)\n",
      "the shape of test_reviews_tv out text TFIDF vectorizer  (10000, 72386)\n"
     ]
    }
   ],
   "source": [
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2), min_df=10)\n",
    "train_reviews_tv = tf_idf_vect.fit_transform(train_preprocessed_reviews)\n",
    "test_reviews_tv = tf_idf_vect.transform(test_preprocessed_reviews)\n",
    "\n",
    "print(\"the type of train and test count vectorizer \",type(train_reviews_tv))\n",
    "print(\"the shape of train_reviews_tv out text TFIDF vectorizer \",train_reviews_tv.get_shape())\n",
    "print(\"the shape of test_reviews_tv out text TFIDF vectorizer \",test_reviews_tv.get_shape())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a logistic regression model\n",
    "lr = LogisticRegression(penalty = 'l2',max_iter = 500,C = 1,random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train A model for Bag of words Vectorizer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bow_lr = lr.fit(train_reviews_cv,train_sentiments)\n",
    "print(Bow_lr)\n",
    "Bow_lr_predict = lr.predict(test_reviews_cv)\n",
    "print(Bow_lr_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train a model for Tfidf vectorizer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_lr = lr.fit(train_reviews_tv,train_sentiments)\n",
    "print(Tfidf_lr)\n",
    "Tfidf_lr_predict = lr.predict(test_reviews_tv)\n",
    "print(Tfidf_lr_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy or The Performance  of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bow_lr_score = accuracy_score(test_sentiments,Bow_lr_predict)\n",
    "print(\"Bow_lr_score : \",Bow_lr_score)\n",
    "\n",
    "Tfidf_lr_score = accuracy_score(test_sentiments,Tfidf_lr_predict)\n",
    "print(\"Tfidf_lr_score : \",Tfidf_lr_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots the confusion matrices given y_i, y_i_hat.\n",
    "def plot_confusion_matrix(test_y, predict_y):\n",
    "    C = confusion_matrix(test_y, predict_y)\n",
    "    A =(((C.T)/(C.sum(axis=1))).T)\n",
    "    B =(C/C.sum(axis=0))\n",
    "    plt.figure(figsize=(20,4))\n",
    "    \n",
    "    labels = [1,2]\n",
    "    # representing A in heatmap format\n",
    "    cmap=sns.light_palette(\"blue\")\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Precision matrix\")\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    # representing B in heatmap format\n",
    "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Recall matrix\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bow_lr_report=classification_report(test_sentiments,Bow_lr_predict,target_names=['Positive','Negative'])\n",
    "print(Bow_lr_report)\n",
    "Bow_lr_report=classification_report(test_sentiments,Tfidf_lr_predict,target_names=['Positive','Negative'])\n",
    "print(Bow_lr_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For Bag of words Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(test_sentiments,Bow_lr_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Observations:-\n",
    "    * This confusion matrix seem to be not good because of its False Negative Rate is high and True Positive rate is very low in confusion matrix.\n",
    "    * There is precision and Recall matrix is also note good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* For Tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(test_sentiments,Tfidf_lr_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Observation:-\n",
    "    * In confusion matrix diagonal boxes are dark blue it means TPR and TNR are high so model perform very well.\n",
    "    * In precision and recall matrix also have digonal dark blue matrix and it is also similar so this is best for model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic gradient descent or Linear support vector machines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* By the Calibrated model that ensure that model is not going to overfit on data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SGDClassifier(loss = 'hinge',penalty = 'l2',random_state = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train a model for Bag of words Vectorizer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(train_reviews_cv,train_sentiments)\n",
    "sig_clf = CalibratedClassifierCV(svm,method ='sigmoid' )\n",
    "sig_clf.fit(train_reviews_cv,train_sentiments)\n",
    "Bow_svm_predict_prob = sig_clf.predict_proba(test_reviews_cv)\n",
    "\n",
    "print(\"The test log loss is : \",log_loss(test_sentiments, Bow_svm_predict_prob, labels=svm.classes_, eps=1e-15))\n",
    "\n",
    "Bow_svm_predict_prob = sig_clf.predict_proba(train_reviews_cv)\n",
    "print(\"The train log loss is : \",log_loss(train_sentiments, Bow_svm_predict_prob, labels=svm.classes_, eps=1e-15))\n",
    "\n",
    "Bow_svm_predict = svm.predict(test_reviews_cv)\n",
    "print(Bow_lr_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train a model for Tfidf Vectorizer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(train_reviews_tv,train_sentiments)\n",
    "sig_clf = CalibratedClassifierCV(svm,method ='sigmoid' )\n",
    "sig_clf.fit(train_reviews_tv,train_sentiments)\n",
    "Tfidf_svm_predict_prob = sig_clf.predict_proba(test_reviews_tv)\n",
    "print(log_loss(test_sentiments, Tfidf_svm_predict_prob, labels=svm.classes_, eps=1e-15))\n",
    "\n",
    "Tfidf_svm_predict_prob = sig_clf.predict_proba(train_reviews_tv)\n",
    "print(log_loss(train_sentiments, Tfidf_svm_predict_prob, labels=svm.classes_, eps=1e-15))\n",
    "\n",
    "print(Tfidf_lr)\n",
    "Tfidf_svm_predict = svm.predict(test_reviews_tv)\n",
    "print(Tfidf_lr_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There is log loss of train and test data is minimum so model is good and not overfit on data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy or The Performance  of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bow_svm_score = accuracy_score(test_sentiments,Bow_svm_predict)\n",
    "print(\"Bow_svm_score : \",Bow_svm_score)\n",
    "\n",
    "Tfidf_svm_score = accuracy_score(test_sentiments,Tfidf_svm_predict)\n",
    "print(\"Tfidf_svm_score : \",Tfidf_svm_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bow_svm_report=classification_report(test_sentiments,Bow_svm_predict,target_names=['Positive','Negative'])\n",
    "print(Bow_svm_report)\n",
    "Tfidf_svm_report=classification_report(test_sentiments,Tfidf_svm_predict,target_names=['Positive','Negative'])\n",
    "print(Tfidf_svm_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(test_sentiments,Bow_svm_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(test_sentiments,Tfidf_svm_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNB = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train a model for Bags of word Vectorizer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bow_MNB = MNB.fit(train_reviews_cv,train_sentiments)\n",
    "print(Bow_MNB)\n",
    "\n",
    "Bow_MNB_predict = MNB.predict(test_reviews_cv)\n",
    "print(Bow_lr_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train a model for Tfidf Vectorizer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_MNB = MNB.fit(train_reviews_tv,train_sentiments)\n",
    "print(Tfidf_MNB)\n",
    "Tfidf_MNB_predict = MNB.predict(test_reviews_tv)\n",
    "print(Tfidf_MNB_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy or The Performance  of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bow_MNB_score = accuracy_score(test_sentiments,Bow_MNB_predict)\n",
    "print(\"Bow_svm_score : \",Bow_MNB_score)\n",
    "\n",
    "Tfidf_MNB_score = accuracy_score(test_sentiments,Tfidf_MNB_predict)\n",
    "print(\"Tfidf_MN_score : \",Tfidf_MNB_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bow_MNB_report=classification_report(test_sentiments,Bow_MNB_predict,target_names=['Positive','Negative'])\n",
    "print(Bow_MNB_report)\n",
    "Tfidf_MNB_report=classification_report(test_sentiments,Tfidf_MNB_predict,target_names=['Positive','Negative'])\n",
    "print(Tfidf_MNB_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(test_sentiments,Tfidf_MNB_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(test_sentiments,Tfidf_MNB_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Conclusions:-\n",
    "    * Bag of words vectorizer is worst vectorizer for any model.\n",
    "    * We can observed that both logistic regression and multinomial naive bayes model performing well compared to linear support vector machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
